{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #FF7B47; padding: 10px; border: thin solid darblue; border-radius: 5px; margin-bottom: 2vh'>\n",
    "    \n",
    "# Session 04 - Project Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #FF7B47; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "     \n",
    "## Overview \n",
    "\n",
    "In this lab, your goal is to learn how to acquire, parse, clean, analyze, and visualize data. Toward this goal, we will address certain question about COVID, and you will scrape data directly from a website. Since real-world problems often require gathering information from a variety of sources, including the Internet, web scraping is a highly useful skill to have. We then ask you to explore, analyze and clean the data before. We'll ask you to come up with some meaningful questions that you can 'ask the data'. Lastly, you will prodcude visualizations that help to identify trends and answer these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "## 1. Obtaining Data\n",
    "    \n",
    "For any given situation or scenario that we wish to understand, we will rely on having relevant data. Here, we are interested in the degree to which the SARS-CoV-2 virus has affected United States citizens (SARS-CoV-2 is the virus that causes the COVID-19 disease). The Centers for Disease Control and Prevention (CDC) provides relevant data from USAFacts.org that includes the number of confirmed COVID-19 cases on a per-county basis. Visit https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/. At the bottom of the web page, in a blue table, you should see a list of every state, each of which has its own web page.\n",
    "\n",
    "In this exercise, we will focus on automating the downloading of each state's data (via Requests). First, as we will do for every Jupyter Notebook, let's import necessary packages that we will use throughout the notebook (i.e., run the cell below)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all potential libraries you might want to use..\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define this for convenience, as every state's url begins with this prefix\n",
    "base_url = 'https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "### Exercise 1.1: Fetching Website data via Requests\n",
    "\n",
    "Fetch the web page located at base_url and save the request's returned object (a Response object) to a variable named home_page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "### Exercise 1.2:\n",
    "Write a line of code that prints to the screen the status of home_page (the web page's returned object). You should receive a code of 200 if the request was successful; then,\n",
    "\n",
    "Write code that prints the entire contents of home_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "### Exercise 1.3:\n",
    "In the cell below, create a new BeautifulSoup object that parses the home_page as an HTML document (can be done with 1 line of code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "### Exercise 1.4:\n",
    "\n",
    "In the cell below, write code that uses the BeautifulSoup object to parse through the home page in order to extract the the covid cases and deaths for each state. for every state. Feel free to use Regular Expressions, in conjunction with any BeautifulSoup parsing. Come up with a data structure or a set of data structures to store that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "### Exercise 1.5:\n",
    "\n",
    "In the cell below, write code that uses the information scraped from the website/table and create at least two meaningful charts. Make sure to ask meaningful questions that your charts should answer. In case you want to perform some data wrangling to prepare the data for your visualizations, we've included some sample code how to sort a dictionary by values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code to sort a dictionary by values\n",
    "markdict = {\"Tom\":67, \"Tina\": 54, \"Akbar\": 87, \"Kane\": 43, \"Divya\":73}\n",
    "marklist = sorted(markdict.items(), key=lambda x:x[1]) # use 1 for sorting values\n",
    "sortdict = dict(marklist)\n",
    "print(sortdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "### Exercise 1.6:\n",
    "\n",
    "In the cell below, write code that allows you to store all the state links from the main website into the state_urls dictionary (the links are bound to the state names in the table you were scraping earlier). Then, write a loop that scrapes all the counties in that state, as well as the 7-day average cases, 7-day average deaths, cases and deaths. For each state, print all that information into a csv file. Ultimately, you should have a csv file for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_urls = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: lightsalmon; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "### Exercise 1.7:\n",
    "\n",
    "Lastly, write a function that has two parameters / takes two arguments: a string that should be the a county name, and another string that should be the path to a csv file containing all the counties of a particular state. The output of the function should be a grouped bar chart for all 4 measures. Each group should contain the value of the county as well as the average value of the state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for grouped bar chart\n",
    "  \n",
    "X = ['Group A','Group B','Group C','Group D']\n",
    "Ygirls = [10,20,20,40]\n",
    "Zboys = [20,30,25,30]\n",
    "  \n",
    "X_axis = np.arange(len(X))\n",
    "  \n",
    "plt.bar(X_axis - 0.2, Ygirls, 0.4, label = 'Girls', edgecolor='black')\n",
    "plt.bar(X_axis + 0.2, Zboys, 0.4, label = 'Boys', edgecolor='black')\n",
    "  \n",
    "plt.xticks(X_axis, X)\n",
    "plt.xlabel(\"Groups\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.title(\"Number of Students in each group\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background: #CBE0A4; padding: 10px; border: thin solid darblue; border-radius: 5px'>\n",
    "\n",
    "### Bonus:\n",
    "\n",
    "For the bonus, we'll up the game a little bit. In the folder 'data' there are three files containing county information about cases, deaths and population. (covid_confirmed_usafacts.csv, covid_deaths_usafacts.csv, covid_county_population_usafacts.csv)\n",
    "Explore these files and then load them using pandas. \n",
    "    \n",
    "Next, come up with some questions you could ask the data set and answer using some preprocessing & data wrangling and, ultimately, visualizations. Note that the data for cases and deaths has a temporal dimension. Try to make use of that information.\n",
    "    \n",
    "For this task, we highly encourage you to work with pandas. We will give you an advanced introduction to pandas in session 5 if time allows it (depending on how comfortable you feel today in session 4). To solve the bonus task during session 4, you will need to study the pandas documentation yourself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/covid_confirmed_usafacts.csv')\n",
    "\n",
    "# sample code how to group by column\n",
    "# data.groupby(by=\"whatever_you_want_to\").sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
